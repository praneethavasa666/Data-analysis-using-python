{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPm3OgIss2m0lzdJW4Lmgz1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"5DTCf4qKOWEz","executionInfo":{"status":"ok","timestamp":1709285132795,"user_tz":-330,"elapsed":5273,"user":{"displayName":"praneetha vasa","userId":"14880014275406581050"}}},"outputs":[],"source":["import numpy as np\n","from keras.models import Sequential\n","from keras.layers import SimpleRNN,Dense,Embedding\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.utils import to_categorical"]},{"cell_type":"code","source":["#Generating an example sequential data\n","sentences=['I eat','I love dance','I hate you','Reccurent Natural Networks']"],"metadata":{"id":"xEGeqxXqVgb-","executionInfo":{"status":"ok","timestamp":1709286247986,"user_tz":-330,"elapsed":629,"user":{"displayName":"praneetha vasa","userId":"14880014275406581050"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#tokenizing the words\n","tokenizer=Tokenizer()\n","tokenizer.fit_on_texts(sentences)\n","total_words=len(tokenizer.word_index) + 1\n","print(total_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6uIbAayyXCBo","executionInfo":{"status":"ok","timestamp":1709286249576,"user_tz":-330,"elapsed":10,"user":{"displayName":"praneetha vasa","userId":"14880014275406581050"}},"outputId":"6bdf0feb-b334-4bae-8159-7d62b6117c12"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["10\n"]}]},{"cell_type":"code","source":["# Creating input sequences and their corresponding next words\n","input_sequences = []\n","for sentence in sentences:\n","    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n","    for i in range(1, len(tokenized_sentence)):\n","        n_gram_sequence = tokenized_sentence[:i+1]\n","        input_sequences.append(n_gram_sequence)\n","input_sequences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VmFjD4MgYnxb","executionInfo":{"status":"ok","timestamp":1709286251092,"user_tz":-330,"elapsed":5,"user":{"displayName":"praneetha vasa","userId":"14880014275406581050"}},"outputId":"1b5a02d7-4993-46ec-81ee-42ac49b6997d"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[1, 2], [1, 3], [1, 3, 4], [1, 5], [1, 5, 6], [7, 8], [7, 8, 9]]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#Padding sequences for consistent input size\n","max_sequence_length = max([len(seq) for seq in input_sequences])\n","input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length,padding='pre')"],"metadata":{"id":"awTGP1BFZtCi","executionInfo":{"status":"ok","timestamp":1709286334303,"user_tz":-330,"elapsed":366,"user":{"displayName":"praneetha vasa","userId":"14880014275406581050"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["input_sequences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43pZQD82Z70D","executionInfo":{"status":"ok","timestamp":1709286358327,"user_tz":-330,"elapsed":419,"user":{"displayName":"praneetha vasa","userId":"14880014275406581050"}},"outputId":"01cd2254-d5a6-4d7a-f30d-d8c894b7a46a"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 1, 2],\n","       [0, 1, 3],\n","       [1, 3, 4],\n","       [0, 1, 5],\n","       [1, 5, 6],\n","       [0, 7, 8],\n","       [7, 8, 9]], dtype=int32)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Creating input and output data\n","X, y = input_sequences[:, :-1], input_sequences[:, -1]\n","y = to_categorical(y, num_classes=total_words)"],"metadata":{"id":"HYXsjR1KaXaH","executionInfo":{"status":"ok","timestamp":1709286459807,"user_tz":-330,"elapsed":403,"user":{"displayName":"praneetha vasa","userId":"14880014275406581050"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Building a simple RNN model\n","model = Sequential()\n","model.add(Embedding(input_dim=total_words, output_dim=50, input_length=max_sequence_length-1))\n","model.add(SimpleRNN(100, return_sequences=True))\n","model.add(SimpleRNN(100))\n","model.add(Dense(total_words, activation='softmax'))"],"metadata":{"id":"WHSWxj9LabS2","executionInfo":{"status":"ok","timestamp":1709286476774,"user_tz":-330,"elapsed":471,"user":{"displayName":"praneetha vasa","userId":"14880014275406581050"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"],"metadata":{"id":"BjoFjcsMapqZ","executionInfo":{"status":"ok","timestamp":1709286615793,"user_tz":-330,"elapsed":523,"user":{"displayName":"praneetha vasa","userId":"14880014275406581050"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["model.fit(X,y,epochs=50,verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pymsgaqbbQ_w","executionInfo":{"status":"ok","timestamp":1709286798541,"user_tz":-330,"elapsed":4454,"user":{"displayName":"praneetha vasa","userId":"14880014275406581050"}},"outputId":"7a079634-75c7-4b30-9771-df637b00168c"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","1/1 - 3s - loss: 2.2909 - accuracy: 0.0000e+00 - 3s/epoch - 3s/step\n","Epoch 2/50\n","1/1 - 0s - loss: 2.2290 - accuracy: 0.4286 - 17ms/epoch - 17ms/step\n","Epoch 3/50\n","1/1 - 0s - loss: 2.1685 - accuracy: 0.4286 - 16ms/epoch - 16ms/step\n","Epoch 4/50\n","1/1 - 0s - loss: 2.1084 - accuracy: 0.5714 - 16ms/epoch - 16ms/step\n","Epoch 5/50\n","1/1 - 0s - loss: 2.0479 - accuracy: 0.5714 - 15ms/epoch - 15ms/step\n","Epoch 6/50\n","1/1 - 0s - loss: 1.9865 - accuracy: 0.5714 - 16ms/epoch - 16ms/step\n","Epoch 7/50\n","1/1 - 0s - loss: 1.9235 - accuracy: 0.5714 - 18ms/epoch - 18ms/step\n","Epoch 8/50\n","1/1 - 0s - loss: 1.8588 - accuracy: 0.5714 - 22ms/epoch - 22ms/step\n","Epoch 9/50\n","1/1 - 0s - loss: 1.7921 - accuracy: 0.5714 - 26ms/epoch - 26ms/step\n","Epoch 10/50\n","1/1 - 0s - loss: 1.7235 - accuracy: 0.5714 - 20ms/epoch - 20ms/step\n","Epoch 11/50\n","1/1 - 0s - loss: 1.6532 - accuracy: 0.5714 - 17ms/epoch - 17ms/step\n","Epoch 12/50\n","1/1 - 0s - loss: 1.5815 - accuracy: 0.5714 - 18ms/epoch - 18ms/step\n","Epoch 13/50\n","1/1 - 0s - loss: 1.5090 - accuracy: 0.5714 - 19ms/epoch - 19ms/step\n","Epoch 14/50\n","1/1 - 0s - loss: 1.4364 - accuracy: 0.5714 - 16ms/epoch - 16ms/step\n","Epoch 15/50\n","1/1 - 0s - loss: 1.3646 - accuracy: 0.7143 - 15ms/epoch - 15ms/step\n","Epoch 16/50\n","1/1 - 0s - loss: 1.2946 - accuracy: 0.7143 - 18ms/epoch - 18ms/step\n","Epoch 17/50\n","1/1 - 0s - loss: 1.2276 - accuracy: 0.7143 - 17ms/epoch - 17ms/step\n","Epoch 18/50\n","1/1 - 0s - loss: 1.1646 - accuracy: 0.7143 - 17ms/epoch - 17ms/step\n","Epoch 19/50\n","1/1 - 0s - loss: 1.1066 - accuracy: 0.7143 - 18ms/epoch - 18ms/step\n","Epoch 20/50\n","1/1 - 0s - loss: 1.0543 - accuracy: 0.7143 - 15ms/epoch - 15ms/step\n","Epoch 21/50\n","1/1 - 0s - loss: 1.0080 - accuracy: 0.7143 - 13ms/epoch - 13ms/step\n","Epoch 22/50\n","1/1 - 0s - loss: 0.9678 - accuracy: 0.7143 - 15ms/epoch - 15ms/step\n","Epoch 23/50\n","1/1 - 0s - loss: 0.9331 - accuracy: 0.7143 - 16ms/epoch - 16ms/step\n","Epoch 24/50\n","1/1 - 0s - loss: 0.9031 - accuracy: 0.7143 - 15ms/epoch - 15ms/step\n","Epoch 25/50\n","1/1 - 0s - loss: 0.8768 - accuracy: 0.7143 - 20ms/epoch - 20ms/step\n","Epoch 26/50\n","1/1 - 0s - loss: 0.8533 - accuracy: 0.7143 - 15ms/epoch - 15ms/step\n","Epoch 27/50\n","1/1 - 0s - loss: 0.8319 - accuracy: 0.7143 - 16ms/epoch - 16ms/step\n","Epoch 28/50\n","1/1 - 0s - loss: 0.8120 - accuracy: 0.7143 - 13ms/epoch - 13ms/step\n","Epoch 29/50\n","1/1 - 0s - loss: 0.7933 - accuracy: 0.7143 - 13ms/epoch - 13ms/step\n","Epoch 30/50\n","1/1 - 0s - loss: 0.7755 - accuracy: 0.7143 - 12ms/epoch - 12ms/step\n","Epoch 31/50\n","1/1 - 0s - loss: 0.7585 - accuracy: 0.7143 - 15ms/epoch - 15ms/step\n","Epoch 32/50\n","1/1 - 0s - loss: 0.7419 - accuracy: 0.7143 - 12ms/epoch - 12ms/step\n","Epoch 33/50\n","1/1 - 0s - loss: 0.7256 - accuracy: 0.7143 - 17ms/epoch - 17ms/step\n","Epoch 34/50\n","1/1 - 0s - loss: 0.7093 - accuracy: 0.7143 - 17ms/epoch - 17ms/step\n","Epoch 35/50\n","1/1 - 0s - loss: 0.6932 - accuracy: 0.7143 - 13ms/epoch - 13ms/step\n","Epoch 36/50\n","1/1 - 0s - loss: 0.6773 - accuracy: 0.7143 - 17ms/epoch - 17ms/step\n","Epoch 37/50\n","1/1 - 0s - loss: 0.6618 - accuracy: 0.7143 - 16ms/epoch - 16ms/step\n","Epoch 38/50\n","1/1 - 0s - loss: 0.6467 - accuracy: 0.7143 - 19ms/epoch - 19ms/step\n","Epoch 39/50\n","1/1 - 0s - loss: 0.6323 - accuracy: 0.7143 - 16ms/epoch - 16ms/step\n","Epoch 40/50\n","1/1 - 0s - loss: 0.6183 - accuracy: 0.7143 - 22ms/epoch - 22ms/step\n","Epoch 41/50\n","1/1 - 0s - loss: 0.6050 - accuracy: 0.7143 - 13ms/epoch - 13ms/step\n","Epoch 42/50\n","1/1 - 0s - loss: 0.5923 - accuracy: 0.7143 - 16ms/epoch - 16ms/step\n","Epoch 43/50\n","1/1 - 0s - loss: 0.5805 - accuracy: 0.7143 - 13ms/epoch - 13ms/step\n","Epoch 44/50\n","1/1 - 0s - loss: 0.5696 - accuracy: 0.7143 - 10ms/epoch - 10ms/step\n","Epoch 45/50\n","1/1 - 0s - loss: 0.5595 - accuracy: 0.7143 - 11ms/epoch - 11ms/step\n","Epoch 46/50\n","1/1 - 0s - loss: 0.5503 - accuracy: 0.7143 - 14ms/epoch - 14ms/step\n","Epoch 47/50\n","1/1 - 0s - loss: 0.5419 - accuracy: 0.7143 - 12ms/epoch - 12ms/step\n","Epoch 48/50\n","1/1 - 0s - loss: 0.5343 - accuracy: 0.7143 - 13ms/epoch - 13ms/step\n","Epoch 49/50\n","1/1 - 0s - loss: 0.5275 - accuracy: 0.7143 - 15ms/epoch - 15ms/step\n","Epoch 50/50\n","1/1 - 0s - loss: 0.5215 - accuracy: 0.7143 - 17ms/epoch - 17ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7b078c3a7460>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["\n","# Generating text using the trained model\n","seed_text = input(\"Enter the starting word: \")\n","next_words = int(input(\"Enter how many words to predict: \"))\n","\n","for _ in range(next_words):\n","    tokenized_seed = tokenizer.texts_to_sequences([seed_text])[0]\n","    tokenized_seed = pad_sequences([tokenized_seed], maxlen=max_sequence_length-1, padding='pre')\n","    predicted_word_index = np.argmax(model.predict(tokenized_seed), axis=-1)\n","    predicted_word = tokenizer.index_word[predicted_word_index[0]]\n","    seed_text += \" \" + predicted_word\n","\n","print(seed_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tkHLFYRXcDDQ","executionInfo":{"status":"ok","timestamp":1709286974708,"user_tz":-330,"elapsed":57295,"user":{"displayName":"praneetha vasa","userId":"14880014275406581050"}},"outputId":"7b4300ce-4534-45bc-e86f-9bf14065f9ed"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the starting word: love\n","Enter how many words to predict: 5\n","1/1 [==============================] - 0s 321ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 20ms/step\n","love natural networks you you you\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"P5uQOMLTcvsH"},"execution_count":null,"outputs":[]}]}